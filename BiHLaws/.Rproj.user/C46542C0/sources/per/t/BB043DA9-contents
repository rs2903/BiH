library(rvest)
library(tidyverse)
library(glue)


# scrap links for all laws ------------------------------------------------


wdr <- getwd() 

seq.page<- seq(1:16)
seq.links <- glue("http://parlament.ba/oLaw/GetOLawsByStatus?page={seq.page}&MandateId=4&Status=-1") %>% 
  enframe(name=NULL)


pb <- progress_estimated(nrow(seq.links))


fn_scrap <- function(x){

  pb$tick()$print()
  
  x %>% 
  read_html() %>% 
  html_nodes("a") %>% 
  html_attr(.,"href") %>% 
  enframe(name=NULL) %>% 
  filter(str_detect(value, "OLawDetails")) %>% 
  mutate(links=paste0("http://parlament.ba",value)) 
  
  }

df.links <- seq.links$value %>% 
  set_names() %>% 
  map_dfr(.,  possibly(fn_scrap, otherwise=NULL), .id="seq.links")


#write.csv2(df.links, paste0(wdr, "/data/2014_2018_law_links.csv"))



# scrap law details based on link list ------------------------------------

df.contents <- df.links$links[1] %>% 
  read_html() %>% 
  html_nodes("td") %>% 
  html_text(.,trim=T) %>% 
  enframe(name=NULL) %>% 
  slice(c(1:13))

df.names<- df.links$links[1] %>% 
  read_html() %>% 
  html_nodes("th") %>% 
  html_text(.,trim=T) %>% 
  enframe(name=NULL) %>% 
  slice(c(1:13))

bind_cols(df.names, df.contents) %>% 
  mutate(chamber=case_when(row_number()>7 ~ "DP",
                           TRUE ~ "PS"))


pb <- dplyr::progress_estimated(nrow(df.links))

fn_scrap_details(df.links$links[1])

fn_scrap_details <- function(x) { 

  pb$tick()$print()
  
df.contents <- x %>% 
  read_html() %>% 
  html_nodes("td") %>% 
  html_text(.,trim=T) %>% 
  enframe(name=NULL) %>% 
  slice(c(1:13))

df.names<- x %>% 
  read_html() %>% 
  html_nodes("th") %>% 
  html_text(.,trim=T) %>% 
  enframe(name=NULL) %>% 
  slice(c(1:13))

bind_cols(df.names, df.contents) %>% 
  mutate(chamber=case_when(row_number()>7 ~ "DP",
                           TRUE ~ "PS"))

}

df.details.all<- df.links$links %>% 
  set_names() %>% 
  map_dfr(.,  possibly(fn_scrap_details, otherwise=NULL), .id="seq.links")

#write_csv2(df.details.all, paste0(wdr,"/data/2014_2018_laws.csv"))


df.details.all.wide <- df.details.all %>% 
  spread(key=value, value=value1, seq.links, chamber)


df.details.all <- readr::read_csv2(paste0(wdr, "/data/2014_2018_laws.csv"))

# law timeline ------------------------------------------------------------

df.links <- readr::read_csv2(paste0(wdr,"/data/2014_2018_law_links.csv"))

pb <- dplyr::progress_estimated(nrow(df.links))


fn_case.details <- function(x)  {
  
    pb$tick()$print()
  
    x %>% 
    read_html() %>% 
    html_nodes("table") %>% 
    html_table(., trim=T, fill=T) %>% 
    
    map(., ~map(., as_tibble)) %>% 
    map(., bind_cols) %>% 
    bind_rows()
      
  }

df.details.all<- df.links$links %>% 
  set_names() %>% 
  map_dfr(.,  possibly(fn_case.details, otherwise=NULL), .id="seq.links")

#write_csv2(df.details.all, paste0(wdr,"/data/2014_2018_law_details.csv"))




# get links to pdfs -------------------------------------------------------


#df.details.all <- readr::read_csv2(paste0(wdr,"/data/2014_2018_law_details.csv"))



df.pdfs <- df.links$links[9] %>% 
    read_html() %>% 
    #html_nodes("li") %>% 
    html_nodes(xpath="//a[contains(text(), 'Listing')]") %>%  #filters links based on text/name of links
    html_attr('href') %>%  #extracts links
    enframe(name=NULL) %>% 
    mutate(link=paste0("http://parlament.ba", value))

library(tabulizer)
u<- df.pdfs$link[1] %>%
  tabulizer::extract_tables() %>% 
  map(., as_tibble) %>% 
  map(., janitor::row_to_names, row_number=2) %>% 
  map(., janitor::clean_names) %>% 
  keep(., map(., nrow) > 0) %>% 
  map_dfr(., bind_rows, .id="law")

pdf.u <- df.pdfs$link[1] %>% 
  pdftools::pdf_text()

pdf.x <- df.pdfs$link[1] %>% 
  tabulizer::extract_tables(method=c("stream"))
